{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49a00648-86d1-4251-848d-1eafdbb9c14e",
   "metadata": {},
   "source": [
    "### The purpose of this project is to build a machine learning system that can automatically identify and categorize key entities in text, such as people, places, and organizations. This is a core task in Natural Language Processing (NLP) known as Named Entity Recognition (NER)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5428d3c3-3769-4165-ae54-1bc27bd83788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('conll2002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d771ee-a07f-49e8-9632-b7e3ef2b165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = nltk.corpus.conll2002.iob_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb74fce4-f5c8-4d20-8c39-e2a36bae22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for cor in corpus:\n",
    "    sent, _, tag = list(zip(*cor))\n",
    "    data.append([sent, tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7407f6e-fbdb-409f-bdd5-07a59971b55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35651"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d99a3f5-203b-4046-94b4-5bfd72ad3371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sao',\n",
       "  'Paulo',\n",
       "  '(',\n",
       "  'Brasil',\n",
       "  ')',\n",
       "  ',',\n",
       "  '23',\n",
       "  'may',\n",
       "  '(',\n",
       "  'EFECOM',\n",
       "  ')',\n",
       "  '.'),\n",
       " ('B-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7845ef-e9ac-4472-84ab-665badb42e07",
   "metadata": {},
   "source": [
    "## Numerization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecaa2a59-3b92-46a3-b114-46db220c46b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "sents, tags = list(zip(*data))\n",
    "vocab  = list(set(flatten(sents)))\n",
    "tagset = list(set(flatten(tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce16433-0900-400a-8879-ee8104e8376c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-LOC', 'B-MISC', 'I-ORG', 'B-LOC', 'I-PER', 'I-MISC', 'B-ORG', 'B-PER', 'O']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "538db3ad-3ffb-443b-8c7e-59642264245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {'<UNK>': 0, '<DUMMY>': 1}\n",
    "for v in vocab:\n",
    "    if word2index.get(v) is None:\n",
    "        word2index[v] = len(word2index)\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "tag2index = {}\n",
    "for v in tagset:\n",
    "    if tag2index.get(v) is None:\n",
    "        tag2index[v] = len(tag2index)\n",
    "index2tag = {v:k for k, v in tag2index.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow Environment",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
